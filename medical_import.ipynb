{
 "metadata": {
  "name": "medical_import"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Great Ormand Street data importer**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "from mayavi import mlab\n",
      "import pybug\n",
      "from pybug.importer.model import import_face\n",
      "from pybug.importer.model import process_with_meshlabserver\n",
      "from pybug.importer.metadata import medical_landmarks\n",
      "from pybug.alignment.rigid import Procrustes\n",
      "from pybug import circlefit\n",
      "from pybug.alignment import rigid\n",
      "from pybug.alignment.nonrigid import TPS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "medical_dir = '/home/jab08/Dropbox/testData/medicaldata/'\n",
      "all_files = os.listdir(medical_dir)\n",
      "med_stls = [f for f in all_files if f.lower().endswith('.stl')]\n",
      "med_lms = [f for f in all_files if f.lower().endswith('.lan')]\n",
      "print 'found ' + `len(med_stls)` + ' medical .stl files'\n",
      "print 'found ' + `len(med_lms)` + ' medical .lan files'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Find the unique identifiers on the lm's and on the stl files*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm_names = [f.split('.')[0].lower() for f in med_lms]\n",
      "lm_names_tuple = [(f.split('.')[0].lower(), f) for f in med_lms]\n",
      "unique_lm_names = set(lm_names)\n",
      "print `len(lm_names)` + ' lm names found'\n",
      "print `len(unique_lm_names)` + ' of which are unique'\n",
      "\n",
      "# npow for the stl landmarks...\n",
      "# find any letters optionally followed by letters before the \n",
      "# file extension\n",
      "prog = re.compile(r'([a-z]+\\d*)[.]', re.IGNORECASE)\n",
      "stl_names = [prog.findall(f)[0].lower() for f in med_stls]\n",
      "stl_names_tuple = [(prog.findall(f)[0].lower(), f) for f in med_stls]\n",
      "unique_stl_names = set(stl_names)\n",
      "print `len(stl_names)` + ' stl names found'\n",
      "print `len(unique_stl_names)` + ' of which are unique'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Find what lm and stl names are fully shared and build a list of tuples, each element* `(stl_filename, matching_lm_filename)`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "faces_with_lms = unique_stl_names.intersection(unique_lm_names)\n",
      "stl_lookup = dict(stl_names_tuple)\n",
      "lm_lookup = dict(lm_names_tuple)\n",
      "paired_stl_lm = []\n",
      "for id_ in faces_with_lms:\n",
      "    paired_stl_lm.append((stl_lookup[id_], lm_lookup[id_]))\n",
      "\n",
      "# now we loop through building faces and attatching the landmarks on them\n",
      "faces = []\n",
      "lms = []\n",
      "for i in paired_stl_lm:\n",
      "    lm_path = os.path.join(medical_dir, i[1])\n",
      "    obj_filename = os.path.splitext(i[0])[0] + '.obj'\n",
      "    obj_path = os.path.join(medical_dir, obj_filename)\n",
      "    lms.append(medical_landmarks(lm_path))\n",
      "    face = pybug.importer.model.import_face(obj_path)\n",
      "    face.lm = medical_landmarks(lm_path)\n",
      "    faces.append(face)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Align the faces landmarks using Generalised Procrustes Analysis*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proc = Procrustes(lms)\n",
      "proc.general_alignment()\n",
      "for face in faces:\n",
      "    face.apply_homogeneous_transform(proc.h_transform_for_source(face.lm))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visulalise aligment\n",
      "mlab.points3d(proc.aligned_sources[:,0,:].flatten(), \n",
      "              proc.aligned_sources[:,1,:].flatten(), \n",
      "              proc.aligned_sources[:,2,:].flatten(), color=(1,1,1), mode='axes') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to define a few special landmarks for us to be able to figure out what direction\n",
      "the faces is orientated in. For these medical landmarks we have:\n",
      "\n",
      "* $l_{16}$ - Centre of forehead\n",
      "* $l_{28}$ - Centre of lower chin\n",
      "* $l_{31}$ - Centre of bottom lip\n",
      "* $l_{32}$ - bottom of right ear\n",
      "* $l_{34}$ - bottom of left ear\n",
      "\n",
      "The approach we take is as follows:\n",
      "\n",
      "1. Generate a vector for the vetical alignment $v_{up} = l_{16} - l_{28}$\n",
      "2. Generate a landmark at the midpoint in the back of the head $l_{back} = (l_{32} + l_{34})/2$\n",
      "3. Generate a vector pointing towards the camera: $v_{front} = l_{31} - l_{back}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lms = proc.aligned_sources\n",
      "xy = np.concatenate([lms[:,0,:].flatten()[:, np.newaxis], \n",
      "                     lms[:,2,:].flatten()[:, np.newaxis]], axis=1)\n",
      "centre, radius = circlefit.circle_fit(xy)\n",
      "centre3d = np.array([centre[0], 0, centre[1]])\n",
      "h_trans_to_circle_centre = rigid.h_translation_matrix(-1.0*centre3d)\n",
      "for face in faces:\n",
      "   face.apply_homogeneous_transform(h_trans_to_circle_centre)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def as_cylindical(c, radius):\n",
      "    cy_coords = np.zeros_like(c)\n",
      "    depth = np.sqrt(c[:,0]**2 + c[:,2]**2) - radius\n",
      "    theta = np.arctan2(-c[:,0], c[:,2])\n",
      "    z = c[:,1]\n",
      "    thetas = theta*radius\n",
      "    cy_coords[:,0] = thetas\n",
      "    cy_coords[:,1] = z\n",
      "    cy_coords[:,2] = depth\n",
      "    return cy_coords\n",
      "\n",
      "def view_cylindical(face): \n",
      "    mlab.triangular_mesh(face.cy_coords[:,0], face.cy_coords[:,1], \n",
      "                         face.cy_coords[:,2], face.tri_index, color=(0.5,0.5,0.5))\n",
      "    mlab.points3d(face.cy_lm[:,0], face.cy_lm[:,1], face.cy_lm[:,2], \n",
      "                  color=(1,1,1), mode='axes')\n",
      "\n",
      "\n",
      "for face in faces:\n",
      "    face.cy_coords = as_cylindical(face.coords, radius)\n",
      "    face.cy_lm = as_cylindical(face.lm, radius)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lms = []\n",
      "for face in faces:\n",
      "    lms.append(face.cy_lm)\n",
      "all_tps = TPS(lms)\n",
      "all_tps.build_TPS_matrices()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}