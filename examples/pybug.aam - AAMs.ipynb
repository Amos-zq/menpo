{
 "metadata": {
  "name": "",
  "signature": "sha256:9bc6081e8378d7888b283f0109b3115c67d85c6bc316c3a0c001350bc2be4165"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Active Appearance Model (AAMs)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Active Appearance Models (AAMs) are generative parametric models that describe the shape and appearance of a certain object class; e.g., the human face. In a typical application, these models are matched against input images to obtain the set of parameters that best describe a particular instance of the object being modelled. \n",
      "\n",
      "The aim of this notebook is to showcase the basic functionality provided by the package `pybug.aam`."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Build a simple AAM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by loading the set of landmarked image that we will be use to build the AAM; in this case, the LFPW training set. Note that the images are rescaled, in order to save valuable memory space, and converted to grayscale (note that the grayscale convertion is optional, RGB images can also be use and, as a matter of fact, in principle, any `n` channel image representation (such as depth and shape images or feature images such as HoG) can also be used)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pybug.io as pio\n",
      "from pybug.landmark import labeller, ibug_68_points, ibug_68_trimesh\n",
      "\n",
      "images = []\n",
      "# load landmarked imarges\n",
      "for i in pio.import_images('/vol/atlas/databases/lfpw/trainset/*.png'):\n",
      "    i.crop_to_landmarks_proportion(0.1)\n",
      "    if i.n_channels == 3:\n",
      "        images.append(i.as_greyscale(mode='luminosity'))\n",
      "    else:\n",
      "        images.append(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "#visualize the first image\n",
      "images[0].landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we will use the `aambuilder` function to build an AAM using the previous images. Most of the time, in order to do that we will need to define a dictionary whose fields specify the type of AAM that will be built. In this first example, there is no real need to explicitely define the entire dictionary, since we will be using the a fairly standard setting, however, for the sake of clarity we will define such dictionary explicitely stating all possible options."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.aam.base import aam_builder\n",
      "from pybug.transform.piecewiseaffine import PiecewiseAffineTransform\n",
      "\n",
      "# set options. Most options are set to their default \n",
      "# values. Obviously, it is in not required to set all \n",
      "# the options to their default values but this is \n",
      "# done here in favour of clarity\n",
      "build_options = {'group': 'PTS', \n",
      "                 'label': 'all',\n",
      "                 'interpolator': 'scipy',\n",
      "                 'reference_shape': None,\n",
      "                 'scale': 1,\n",
      "                 'boundary': 3,\n",
      "                 'transform_cls': PiecewiseAffineTransform,\n",
      "                 'trilist': None,\n",
      "                 'patch_size': None,\n",
      "                 'n_levels': 1, \n",
      "                 'downscale': 2,\n",
      "                 'scaled_reference_frames': False,\n",
      "                 'features': None,\n",
      "                 'max_shape_components': 25,\n",
      "                 'max_appearance_components': 250}\n",
      "# build aam\n",
      "aam = aam_builder(images, **build_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The returned AAM object allows us to, for example, generate random AAM instances. Note that we can also specify particular shape and appearance parameters values from which to generate the instance. \n",
      "\n",
      "Notes: \n",
      "\n",
      "- In the final verison of this Notebook one should be able to also print the AAM object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "# For some currently unknown reason sometimes \n",
      "# the components of the shape model are complex\n",
      "# (although the imaginary part is 0...). Until \n",
      "# this looked up and understood, it is safer to \n",
      "# always manually convert them to be real. \n",
      "# This issue should be solved before the PR \n",
      "# goes through.  \n",
      "aam.shape_models[0]._components = np.real(aam.shape_models[0]._components)\n",
      "aam.shape_models[0]._eigenvalues = np.real(aam.shape_models[0]._eigenvalues)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "# random instance\n",
      "aam.instance().view() \n",
      "# handpicked intance\n",
      "aam.instance(shape_weights=[1,2,3], \n",
      "             appearance_weights=[1,2,3,4,5]).view_new()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with any other python object we can also save the AAM for later use using `pickle`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "# set path\n",
      "path =  '/data/PhD/Models/'\n",
      "# set name\n",
      "name = 'aam_' + 'lfpw_' + 'default'\n",
      "\n",
      "# save aam\n",
      "pickle.dump({'aam': aam}, open(path + name, 'wb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And load it back."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "# set path\n",
      "path =  '/data/PhD/Models/'\n",
      "# set name\n",
      "name = 'aam_' + 'lfpw_' + 'default'\n",
      "\n",
      "# load aam\n",
      "obj = pickle.load(open(path + name, \"rb\"))\n",
      "aam = obj['aam']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fit a simple AAM "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More importantly, we can now fit the AAM object to a novel image using all the methods in the `pybug.lucaskanade` package. We will start by loading the novel image (i.e. and image that was not used for building the AAM), for example, the BreakingBad image in the PyBug's data folder. Note that the current implementation requires the image to be greyscale (because the AAM was built using greayscale images) in order to be fitted. Finally, we also crop the BreakindBad image to make the landmarks easily visible to the user. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "breakingbad = pio.import_builtin_asset('breakingbad.jpg')\n",
      "breakingbad = breakingbad.as_greyscale(mode='luminosity')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "breakingbad.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "breakingbad.crop_to_landmarks_proportion(0.3, group='PTS')\n",
      "breakingbad.landmarks['PTS'].view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we will need to initialize the AAM Lucas-Kanade fitting procedure. We can do this using the method `initialize_lk`. This method will allow us to set different options regarding the fitting procedure, from the specific algorithm to be used to the number of components that will be optimize. Although in this example we will only use the default fitting setting, for the sake of clarity, we will define an explicit dictionary containing all the options."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.aam.fitter import LucasKanadeAAMFitter\n",
      "from pybug.lucaskanade.appearance import AlternatingInverseCompositional\n",
      "from pybug.lucaskanade.residual import LSIntensity\n",
      "from pybug.transform.modeldriven import OrthoMDTransform\n",
      "from pybug.transform.affine import SimilarityTransform\n",
      "\n",
      "# set fitting options. As before we favour \n",
      "# clarity by explicitely stating all possible\n",
      "# options\n",
      "fitting_setting_options = \\\n",
      "    {'lk_algorithm': AlternatingInverseCompositional,\n",
      "     'residual': LSIntensity,\n",
      "     'md_transform_cls': OrthoMDTransform,\n",
      "     'global_transform_cls': SimilarityTransform,\n",
      "     'n_shape': 10, \n",
      "     'n_appearance': 100}\n",
      "\n",
      "# initialize Lucas-Kanade aam fitting\n",
      "lk_aam_fitter = LucasKanadeAAMFitter(aam, **fitting_setting_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now attempt to fit the greayscale version of the BreakingBad image using the method `lk_fit_landmarked_image` in the AAM object. Note that, because the BreakingBad image is annotated, we will initialize the fitting procedure using by perturbing the original ground truth annotation with white noise. Again, in order to favor clarity, an explicit dictionary will be used to set this method's options (do not worry, there will not be more explicit dictionaries)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitting_options = {'group': 'PTS',\n",
      "                   'label': 'all',\n",
      "                   'runs': 1, \n",
      "                   'noise_std': 0.0,\n",
      "                   'max_iters': 50,\n",
      "                   'rotation': False,\n",
      "                   'verbose': True, \n",
      "                   'view': True}\n",
      "\n",
      "# fit test images\n",
      "fitting_list = lk_aam_fitter.fit_image(breakingbad, **fitting_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not surprisingly the alignment did not quite work. Do not worry! This was just the most basic AAM we could build ;-).\n",
      "\n",
      "Note that the `fit_image` method returns an object of type FittingList. Note that because `runs=1`, in this case this list contains a single `Fitting` object. Apart from containing the final result, i.e. the fitted shape, Fitting objects allow us to analyse and visualize interesting aspect of the fitting process, e.g:\n",
      "\n",
      "- Obtain the final fitting result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aam_fitting = fitting_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_shape = aam_fitting.final_shape\n",
      "\n",
      "%matplotlib inline\n",
      "final_shape.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Visualize it on top of the fitted image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.view_final_fitting()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Visualize the initial position from which the fitting started:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.view_initialization()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Visualize the sequence of warped images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "aam_fitting.view_warped_images()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Visualize the sequence of apperance reconstructions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "aam_fitting.view_appearance_reconstructions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Visualize the sequence of error images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "aam_fitting.view_error_images()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Plot the error evolution, i.e. the error between the ground truth annotation and the fitted shape per iteration. Note that this is possible only because the original image is annotated."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.plot_error(color_list=['b'], marker_list=['*'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Building a more powerful AAM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `ammbuilder` function allows us to automatically build many different types of AAMs by simply specifying the right options. \n",
      "\n",
      "For example, using the same LFPW training data and similar fitting options as before, we can build and fit a Multiresolution HoG-AAM that will have no problem in correctly fitting the BreakingBad image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# delete previous aam in order to save \n",
      "# valuable memory space\n",
      "del aam"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# label images\n",
      "labeller(images, 'PTS', ibug_68_trimesh);\n",
      "\n",
      "# set options\n",
      "build_options = {'group': 'PTS',  \n",
      "                 'trilist': images[0].landmarks['ibug_68_trimesh'].lms.trilist,\n",
      "                 'n_levels': 3,\n",
      "                 'downscale': 2,\n",
      "                 'features': ('hog', {'window_step_vertical':3, 'window_step_horizontal':3}),\n",
      "                 'max_shape_components': 25,\n",
      "                 'max_appearance_components': 250}\n",
      "# build aam\n",
      "aam = aam_builder(images, **build_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "aam.shape_models[0]._components = np.real(aam.shape_models[0]._components)\n",
      "aam.shape_models[1]._components = np.real(aam.shape_models[1]._components)\n",
      "aam.shape_models[2]._components = np.real(aam.shape_models[1]._components)\n",
      "aam.shape_models[0]._eigenvalues = np.real(aam.shape_models[0]._eigenvalues)\n",
      "aam.shape_models[1]._eigenvalues = np.real(aam.shape_models[1]._eigenvalues)\n",
      "aam.shape_models[2]._eigenvalues = np.real(aam.shape_models[1]._eigenvalues)\n",
      "\n",
      "# lowest resolution level\n",
      "%matplotlib inline\n",
      "aam.instance(level=0).view(channels=0) \n",
      "# middle resolution level\n",
      "aam.instance(level=1).view_new(channels=0)\n",
      "# highest resolution level\n",
      "aam.instance().view_new(channels=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set fitting options. As before we favour \n",
      "# clarity by explicitely stating all possible\n",
      "# options\n",
      "fitting_setting_options = \\\n",
      "    {'n_shape': [3, 6, 12], \n",
      "     'n_appearance': 100}\n",
      "\n",
      "# initialize Lucas-Kanade aam fitting\n",
      "lk_aam_fitter = LucasKanadeAAMFitter(aam, **fitting_setting_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fitting_options = {'max_iters': 20,\n",
      "                   'rotation': False}\n",
      "\n",
      "# fit test images\n",
      "fitting_list = lk_aam_fitter.fit_image(breakingbad, **fitting_options)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aam_fitting = fitting_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.view_initialization()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.view_final_fitting()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "aam_fitting.view_warped_images()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "aam_fitting.view_error_images(channels=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "aam_fitting.plot_error(color_list=['b'], marker_list=['*'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}