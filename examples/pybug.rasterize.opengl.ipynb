{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pybug.rasterize.opengl import OpenGLRasterizer\n",
      "import matplotlib.pyplot as plt\n",
      "import pybug.io as pio\n",
      "from pybug.transform import Translation, Scale\n",
      "from pybug.image import MaskedImage\n",
      "\n",
      "def mesh_to_render_spec(mesh):\n",
      "    # get data in the correct formats\n",
      "    # points need to be homogeneous, and texture needs to have an alpha channel\n",
      "    points = np.require(mesh.points, dtype=np.float32, requirements='c')\n",
      "    trilist = np.require(mesh.trilist, dtype=np.uint32, requirements='c')\n",
      "    texture = np.require(mesh.texture.pixels, dtype=np.float32, requirements='c')\n",
      "    tcoords = np.require(mesh.tcoords.points, dtype=np.float32, requirements='c')\n",
      "    f3v_data = points\n",
      "    return points, f3v_data, trilist, tcoords, texture \n",
      "\n",
      "def render_mesh(mesh, renderer):\n",
      "    rgb_fb, f3v_fb = r.render_offscreen_rgb(*mesh_to_render_spec(mesh))\n",
      "    mask_array = ~rgb_fb[..., 3].astype(np.bool)\n",
      "    return MaskedImage(rgb_fb[..., :3].copy(), mask=mask_array), MaskedImage(f3v_fb.copy(),mask=mask_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**RENDERING A FACE**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we ensure the mesh fits into the clipping space `-1 < x,y,z < 1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mesh = pio.import_mesh('/vol/hci2/Databases/video/BU-4DFE/F001/Angry/000.wrl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib wx\n",
      "mesh.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mayavi.mlab as mlab\n",
      "mlab_scene = mlab.gcf().scene\n",
      "\n",
      "VM = mlab_scene.camera.view_transform_matrix.to_array().astype(np.float32)\n",
      "\n",
      "scene_size = tuple(mlab_scene.get_size())\n",
      "clip_range = mlab_scene.camera.clipping_range\n",
      "aspect_ratio = float(scene_size[0])/float(scene_size[1])\n",
      "\n",
      "# this actually just gets a vtk matrix object, we can't really do anything with it yet\n",
      "P = mlab_scene.camera.get_perspective_transform_matrix(aspect_ratio, \n",
      "                                                       -1,\n",
      "                                                       1).to_array().astype(np.float32)\n",
      "\n",
      "# p = scene.camera.get_perspective_transform_matrix(3.0/4.0, 0.1, 1000).to_array().astype(np.float32)\n",
      "c_postion, focal_point_position = mlab.move()\n",
      "print 'scene size: {} (aspect ratio: {})'.format(scene_size, aspect_ratio)\n",
      "print 'clip range: {}'.format(clip_range)\n",
      "\n",
      "h_points = np.concatenate([mesh.points, np.ones(mesh.points.shape[0])[..., None]], axis=1).T\n",
      "points_after_VM = np.dot(VM, h_points)\n",
      "points_in_clip_space = np.dot(P, points_after_VM)\n",
      "points_after_clip_divide = (points_in_clip_space / points_in_clip_space[3])[:3]\n",
      "\n",
      "r = OpenGLRasterizer(*scene_size)\n",
      "r.set_projection_matrix(np.ascontiguousarray(P))\n",
      "r.set_view_matrix(np.ascontiguousarray(VM))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rgb_img, float_im = render_mesh(mesh, r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q%matplotlib inline\n",
      "plt.hist(rgb_img.pixels.ravel(), bins=1000);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "rgb_img.view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**How long does it take?**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit render_mesh(mesh, r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Converting a mesh for OpenGL renderering - timings**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "render_args = mesh_to_render_spec(mesh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit mesh_to_render_spec(mesh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consituent costs..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np.require(mesh.points, dtype=np.float32, requirements='c')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np.require(mesh.trilist, dtype=np.uint32, requirements='c')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit np.require(mesh.tcoords.points, dtype=np.float32, requirements='c')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Rendering the data - OpenGL only**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit r.render_offscreen_rgb(*render_args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print r.get_projection_matrix()\n",
      "print r.get_model_matrix()\n",
      "print r.get_view_matrix()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**RENDERING A SIMPLE SQUARE**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "# make a texture - half red, half blue\n",
      "texture = np.empty((64, 64, 4), dtype=np.uint8)\n",
      "texture[..., 3] = 255\n",
      "texture[:32,:,:3] = np.array([255, 0, 0], dtype=np.uint8)\n",
      "texture[32:,:,:3] = np.array([0, 0, 255], dtype=np.uint8)\n",
      "\n",
      "# unit square (0,0) -> (1, 1)\n",
      "points = np.array([[0, 0, 0, 1.],\n",
      "                   [1, 0, 0, 1.],\n",
      "                   [1, 1, 0, 1],\n",
      "                   [0, 1, 0, 1]], dtype=np.double)\n",
      "trilist = np.array([[0,1,3],\n",
      "                    [1,2,3]], dtype=np.uint32)\n",
      "tcoords = np.array([[0, 0],\n",
      "                    [1, 0],\n",
      "                    [1, 1],\n",
      "                    [0, 1]], dtype=np.float32)\n",
      "pixels = r.render_offscreen_rgb(points, trilist, tcoords, texture)\n",
      "# pixels will need to be flipped!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}